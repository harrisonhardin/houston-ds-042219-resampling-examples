{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples and applications of Kolmogorov-Smirnov tests, Permutation tests, and Monte Carlo resampling techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolmogorov-Smirnov test\n",
    "\n",
    "The KS test:\n",
    "- is only valid for continuous distributions\n",
    "- tends to be more sensitive near the center of the distribution than at the tails\n",
    "- requires a fully specified distribution. That is, if location, scale, and shape parameters are estimated from the data, the critical region of the K-S test is no longer valid. \n",
    "\n",
    "The Kolmogorov-Smirnov test can be used to answer the following types of questions:\n",
    "\n",
    "- Are the data from a normal distribution?\n",
    "- Are the data from a log-normal distribution?\n",
    "- Are the data from a Weibull distribution?\n",
    "- Are the data from an exponential distribution?\n",
    "- Are the data from a logistic distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a crack at some quick examples to famliarize ourselves with the KS test.\n",
    "\n",
    "###  1 sample Kolmogorov-Smirnov test\n",
    "\n",
    "The 1 sample Kolmogorov-Smirnov test compares the distribution G(x) of an observed random variable against a given distribution F(x). \n",
    "\n",
    "Under the null hypothesis the two distributions are identical, G(x)=F(x). \n",
    "\n",
    "The alternative hypothesis can be either ‘two-sided’ (default), ‘less’ or ‘greater’.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.4443560271592436, pvalue=0.038850142705171065)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(-15, 15, 9)\n",
    "stats.kstest(x, 'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.058352892479417884, pvalue=0.8853119094415126)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(987654321) # set random seed to get the same result\n",
    "stats.kstest('norm', False, N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above lines are equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.058352892479417884, pvalue=0.8853119094415126)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(987654321)\n",
    "stats.kstest(stats.norm.rvs(size=100), 'norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test against one-sided alternative hypothesis\n",
    "\n",
    "Shift distribution to larger values, so that cdf_dgp(x) < norm.cdf(x):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.12464329735846891, pvalue=0.04098916407764175)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(987654321)\n",
    "x = stats.norm.rvs(loc=0.2, size=100)\n",
    "stats.kstest(x,'norm', alternative = 'less')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reject equal distribution against alternative hypothesis: less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.007211523321631108, pvalue=0.985311585903964)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.kstest(x,'norm', alternative = 'greater')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don’t reject equal distribution against alternative hypothesis: greater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.12464329735846891, pvalue=0.08944488871182082)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.kstest(x,'norm', mode='asymp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing t distributed random variables against normal distribution\n",
    "\n",
    "With 100 degrees of freedom the t distribution looks close to the normal distribution, and the K-S test does not reject the hypothesis that the sample came from the normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.07201892916547126, pvalue=0.6763006286247917)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(987654321)\n",
    "stats.kstest(stats.t.rvs(100,size=100),'norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 3 degrees of freedom the t distribution looks sufficiently different from the normal distribution, that we can reject the hypothesis that the sample came from the normal distribution at the 10% level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.131016895759829, pvalue=0.058826222555312224)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(987654321)\n",
    "stats.kstest(stats.t.rvs(3,size=100),'norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 sample KS test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345678)  #fix random seed to get the same result\n",
    "n1 = 200  # size of first sample\n",
    "n2 = 300  # size of second sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a different distribution, we can reject the null hypothesis since the pvalue is below 1%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.20833333333333337, pvalue=4.667497551580699e-05)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvs1 = stats.norm.rvs(size=n1, loc=0., scale=1)\n",
    "rvs2 = stats.norm.rvs(size=n2, loc=0.5, scale=1.5)\n",
    "stats.ks_2samp(rvs1, rvs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a slightly different distribution, we cannot reject the null hypothesis at a 10% or lower alpha since the p-value at 0.144 is higher than 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.10333333333333333, pvalue=0.14498781825751686)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvs3 = stats.norm.rvs(size=n2, loc=0.01, scale=1.0)\n",
    "stats.ks_2samp(rvs1, rvs3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an identical distribution, we cannot reject the null hypothesis since the p-value is high, 41%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.07999999999999996, pvalue=0.4112694972985972)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvs4 = stats.norm.rvs(size=n2, loc=0.0, scale=1.0)\n",
    "stats.ks_2samp(rvs1, rvs4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KS tests are helpful to use when you are interested in using a particular statistical test that demands/assumes a particular distribution. They can be used to verify your results in this way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling techniques\n",
    "\n",
    "A method that consists of drawing repeated samples from the original data samples.\n",
    "\n",
    "#### Why do we want to do this?\n",
    "\n",
    "There are three instances when we would want to use resampling:\n",
    "\n",
    "- When we want to estimate the precision of sample statistics (medians, variances, percentiles)\n",
    "- When exchanging labels on data points when performing significance tests\n",
    "- When we want to validate models by using random subsets\n",
    "\n",
    "#### How do we resample our data?\n",
    "\n",
    "- Randomization (Permutation) Test\n",
    "- Monte Carlo Simulation\n",
    "- Bootstrapping\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permutation testing\n",
    "\n",
    "Permutation tests are a group of nonparametric statistics. Here we use a permutation test to test the null hypothesis that two different groups come from the same distribution.\n",
    "\n",
    "In a permutation test, you are essentially just shuffling your data in order to get a randomized selection of your data, so you can test things like whether or not two sets of data come from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array([94,197,16,38,99,141,23])\n",
    "y = np.array([52,104,146,10,51,30,40,27,46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.63492063492064"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_hat = z.mean() - y.mean()\n",
    "theta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to run your permutation\n",
    "\n",
    "def run_permutation_test(pooled,sizeZ,sizeY,delta):\n",
    "    #randomize all the pooled data from arrays y and z\n",
    "    np.random.shuffle(pooled)\n",
    "    #grab data the length of z\n",
    "    starZ = pooled[:sizeZ]\n",
    "    #grab the rest of the data the length of y\n",
    "    starY = pooled[-sizeY:]\n",
    "    #find the difference in the mean\n",
    "    return starZ.mean() - starY.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14459999999999995"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled = np.hstack([z,y])\n",
    "delta = z.mean() - y.mean()\n",
    "numSamples = 10000\n",
    "estimates = np.array(list(map(lambda x: run_permutation_test(pooled,z.size,y.size,delta),range(numSamples))))\n",
    "diffCount = len(np.where(estimates < delta)[0])\n",
    "hat_sig_perm = 1.0 - (float(diffCount)/float(numSamples))\n",
    "hat_sig_perm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we fail to reject the null hypothesis.\n",
    "\n",
    "Here is another tool that I find useful sometimes. It is a library called mlxtend.\n",
    "\n",
    "There are some very helpful functions in this package. If you do not want to use this tool, that is also okay! The results are a bit different sometimes, but that is because the tools are programmed a bit differently. I have provided the link to the github repo with all of this code at the bottom of the notebook if you're interested in investigating that further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install mlxtend (if you want)\n",
    "\n",
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27604895104895105\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.evaluate import permutation_test\n",
    "\n",
    "p_value = permutation_test(z, y,\n",
    "                           num_rounds=10000,\n",
    "                           seed=0)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fail to reject the null hypothesis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Simulation\n",
    "\n",
    "#### What is Monte Carlo simulation?\n",
    "\n",
    "Monte Carlo simulation is a method used to model probabilistic systems and establish the odds for a variety of outcomes.\n",
    "\n",
    "For example:\n",
    "\n",
    "![https://www.greatlakespondscapes.com/wp-content/uploads/GreatLakesPondscapes-27_480x320_acf_cropped.jpg](https://www.greatlakespondscapes.com/wp-content/uploads/GreatLakesPondscapes-27_480x320_acf_cropped.jpg)\n",
    "\n",
    "You have a rectangular yard that is 10 by 15 feet. There is a pond in the middle of irregular shape and you want to know the area of the pond. \n",
    "\n",
    "You start throwing small stones toward the yard randomly and record the frequency of stone landing on water versus dry land. The portion of stones landing on water multiplied by the entire area of the backyard is the answer to the original question. \n",
    "\n",
    "For example, if you threw 100 stones and 43 lands on water, then your estimation would be 10 times 15 times 0.43. This is essentially the essence of Monte Carlo: evaluating and averaging randomly drawn samples.\n",
    "\n",
    "\n",
    "#### Generalized steps to Monte Carlo simulation\n",
    "\n",
    "1. Construct a simulated “universe” of some other randomizing mechanism whose composition is similar to the universe whose behavior we wish to describe and investigate, like dice or cards or coins. The term “universe” refers to the system that is relevant for a single simple event. In this step, you will do the following:\n",
    "    - Decide which symbols will stand for the elements of the universe you will simulate.\n",
    "    - Determine whether the sampling will be with or without replacement. (This can be ambiguous in a complex modeling situation.) Note: if trials are independent you will sample with replacement.\n",
    "2. Specify the procedure that produces a pseudo-sample  which simulates the real-life sample in which we are interested. That is, specify the procedural rules by which the sample is drawn from the simulated universe. These rules must correspond to the behavior of the real universe in which you are interested. To put it another way, the simulation procedure must produce simple experimental events with the same probabilities that the simple events have in the real world.\n",
    "3. If several simple events must be combined into a composite event, and if the composite event was not described in the procedure in step 2, describe it now.\n",
    "4. Calculate the probability of interest from the tabulation of outcomes of the resampling trials.\n",
    "\n",
    "\n",
    "Let's try applying these generalized rules to some specific situations.\n",
    "\n",
    "If the birth rate ratio of boys to girls is 51:49, what is the probability of having two children who are both girls. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a sample universe. Here we have just created a list of 100 babies \n",
    "#that are boys or girls. This event can, however, be represented by the same mechanic as\n",
    "#flipping a coin, too.\n",
    "\n",
    "babies = []\n",
    "for i in range(0,49):\n",
    "    babies += ['g']\n",
    "for i in range(0,51):\n",
    "    babies += ['b']\n",
    "\n",
    "\n",
    "Answer = 0\n",
    "Simulations = 1000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run Monte Carlo simulation\n",
    "for i in range(0,Simulations):\n",
    "    girls = random.sample(babies, 2)\n",
    "    if (girls[0]== \"g\" and girls[1]==\"g\"):\n",
    "        Answer += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.237327\n"
     ]
    }
   ],
   "source": [
    "#get resulting probablity\n",
    "Result = Answer/Simulations\n",
    "print(Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do note, if you run the above cells again, you will yield a slightly different result, becuase there is a note of randomness to this technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrap resampling\n",
    "\n",
    "Bootstrap is a special case of the Monte Carlo simulation. The differences between the bootstrap and Monte Carlo methods are:\n",
    "- Monte Carlo simulation is based on a random number and a a priori distribution form of data\n",
    "- Bootstrap resamples with replacement on the real data.\n",
    "\n",
    "Samples are drawn from the dataset with replacement (allowing the same sample to appear more than once in the sample), where those instances not drawn into the data sample may be used for the test set.\n",
    "\n",
    "The most widely used resampling method, it estimates the sampling distribution of an estimator by sampling with replacement from the original estimate, most often with the purpose of deriving robust estimates of standard errors and confidence intervals of a population parameter.\n",
    "\n",
    "The steps for bootstrap resampling are the following, generally:\n",
    "- Start with a sample from population with sample size n.\n",
    "- Draw a sample from the original sample data with replacement of size n, where each re-sampled sample is called a Bootstrap Sample.\n",
    "- Evaluate the statistics of the metric you are estimating for each bootstrap sample.\n",
    "- Construct a sampling distribution with these B Bootstrap statistics and use it to make further statistical inference, such as:\n",
    "  - Estimating the standard error of the statistics of your metric.\n",
    "  - Obtaining a Confidence Interval for your metric.\n",
    "\n",
    "\n",
    "Imagine that you want to summarize how many times a day people are on their phone on the 4th floor, where the total number of people is 100 (for sake of ease). Over the next few days, you ask 30 others on the 4th floor how many times they are on their phone in a day. From these responses,  you calculated the mean of these 30 responses and got an estimate for phone calls  is 15 times a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27, 17,  1, 10, 21, 14, 23,  1, 11,  7, 17, 26,  3,  7,  2, 19, 23,\n",
       "       29,  1,  8,  9, 27, 23, 14, 27,  1, 20,  6,  3,  6])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct a population pickups for our lab\n",
    "np.random.seed(42)\n",
    "calls = np.random.randint(0,30 , size=100)\n",
    "calls\n",
    "\n",
    "# draw a sample from population\n",
    "sample = np.random.choice(calls, size=30)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.63"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calls.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.988498206040873"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calls.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap for mean\n",
    "boot_means = []\n",
    "for _ in range(10000):\n",
    "    bootsample = np.random.choice(sample,size=30, replace=True)\n",
    "    boot_means.append(bootsample.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated mean of mean\n",
    "bootmean = np.mean(boot_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated standard deviation of mean\n",
    "bootmean_std = np.std(boot_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.63, 13.437966666666668)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulated mean VS true mean\n",
    "(calls.mean(), bootmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6410677418477682, 1.6943836896576223)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the theorical standard error and simulated standard error\n",
    "(calls.std()/(30 ** 0.5), bootmean_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "\n",
    "- https://towardsdatascience.com/monte-carlo-simulations-with-python-part-1-f5627b7d60b0\n",
    "- https://towardsdatascience.com/the-house-always-wins-monte-carlo-simulation-eb82787da2a3\n",
    "\n",
    "- https://github.com/rasbt/mlxtend Github repo for mlxtend. This package has very useful functions within it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
